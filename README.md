
## 简单介绍
	这里的代码主要是采用text-rank算法计算文本摘要，另外优势在于引入了词向量和权重倾斜
	使得文章摘要提取效果得到了非常显著的提升。

## 注意
	注意：由于github文件有大小限制，这里没有上传完整的词向量模型，所以无法直接运行，需要补充textrank4zh/word_model目录中的数据。
	如果有需要，可在我的百度网盘下载，或者自己训练放入textrank4zh/word_model文件夹。

	链接: https://pan.baidu.com/s/1o9RlASq 密码: 4kug

## 依赖
	jieba >= 0.35  
	numpy >= 1.7.1  
	networkx >= 1.9.1
	gensim

## 兼容性
适用于Python 2.7，已经测试过

## 原理

	关于原理以及本代码实现的效果优化可见我上传的论文 《text-rank提取文章摘要与结果优化.doc》
	阅读完对使用有很大的帮助
	
## 使用方式
	python ceshi.py n
	直接在代码目录执行 python ceshi.py n (n就是我们要生成的摘要的句数)

	ceshi.py 只是提供了使用的范例，打印出摘要结果，具体可以自己修改。

## 说明:
	(1) 这里使用的词向量是基于自己在基维百科进行的语料训练，生成的 60 维。
	如果有更好的词向量，可以自行替换
    
	(2) 在ceshi.py 中加入了倾斜因子，倾斜因子是针对不同文章的处理。取值范围 (0,1]，具体说明如下：
	我们知道，对于不同类别的文章，结构会很不一样，如果说散文，那么往往中心思想只有一个，且段落之间相对联系紧密，都是体现一个思想，描述一个问题。
	这种情况下，我们不采用权重倾斜也是没太大问题。
	但是，针对于那种新闻，资讯类的文章，往往并不体现一个主题，并且段落之间联系可能不是那么紧密，但是段落本身结构更紧凑，往往会在段落开始就一针见血。
	如果我们还采用相似度作为句子与句子之间的链接关系，往往获取的摘要不是那么理想。
	针对这种文章，同时又考虑到通用性。我们可以加入一个加权因子，即对每个段落的段首做适当的加权，往后逐渐衰减，呈梯度模型。
    
	在ceshi.py 有一个 decay_rate 参数，取值 (0,1]，值越小，倾斜越大，默认为 1 代表无任何倾斜，可处理一般文章。
	(在context目录中，有很多文章可供测试，里面比如 0003 是一般性散文,这时可设decay_rate = 1.0)
    
	当需要处理咨询，新闻类比较结构紧凑的文章时，我们就加入适当的倾斜因子，一般设成0.8-0.9即可。这样的模型更加通用且实用。
	(我们可以用context目录中0015是金融咨询测试，当生成摘要时，取 decay_rate = 0.8 比 1.0 时效果好很多)



